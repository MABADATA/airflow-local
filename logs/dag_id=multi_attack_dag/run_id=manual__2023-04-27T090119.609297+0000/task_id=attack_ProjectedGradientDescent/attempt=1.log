[2023-04-27 09:09:34,363] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: multi_attack_dag.attack_ProjectedGradientDescent manual__2023-04-27T09:01:19.609297+00:00 [queued]>
[2023-04-27 09:09:34,612] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: multi_attack_dag.attack_ProjectedGradientDescent manual__2023-04-27T09:01:19.609297+00:00 [queued]>
[2023-04-27 09:09:34,621] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-04-27 09:09:34,625] {taskinstance.py:1357} INFO - Starting attempt 1 of 2
[2023-04-27 09:09:34,631] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-04-27 09:09:34,783] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): attack_ProjectedGradientDescent> on 2023-04-27 09:01:19.609297+00:00
[2023-04-27 09:09:34,810] {standard_task_runner.py:52} INFO - Started process 2862 to run task
[2023-04-27 09:09:34,816] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'multi_attack_dag', 'attack_ProjectedGradientDescent', 'manual__2023-04-27T09:01:19.609297+00:00', '--job-id', '6473', '--raw', '--subdir', 'DAGS_FOLDER/attack_dag.py', '--cfg-path', '/tmp/tmpd9owj6f5', '--error-file', '/tmp/tmpf_7vutc1']
[2023-04-27 09:09:34,893] {standard_task_runner.py:80} INFO - Job 6473: Subtask attack_ProjectedGradientDescent
[2023-04-27 09:09:35,365] {task_command.py:369} INFO - Running <TaskInstance: multi_attack_dag.attack_ProjectedGradientDescent manual__2023-04-27T09:01:19.609297+00:00 [running]> on host e7e31d5a6603
[2023-04-27 09:09:35,962] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=multi_attack_dag
AIRFLOW_CTX_TASK_ID=attack_ProjectedGradientDescent
AIRFLOW_CTX_EXECUTION_DATE=2023-04-27T09:01:19.609297+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-04-27T09:01:19.609297+00:00
[2023-04-27 09:09:35,974] {transport.py:157} INFO - Attempting refresh to obtain initial access_token
[2023-04-27 09:09:35,984] {client.py:777} INFO - Refreshing access_token
[2023-04-27 09:09:36,697] {transport.py:157} INFO - Attempting refresh to obtain initial access_token
[2023-04-27 09:09:36,704] {client.py:777} INFO - Refreshing access_token
[2023-04-27 09:09:56,712] {pytorch.py:1198} INFO - Inferred 5 hidden layers on PyTorch classifier.
[2023-04-27 09:12:56,587] {attack_dag.py:642} INFO - Optimizing...
[2023-04-27 09:12:56,591] {logging_mixin.py:115} INFO - I am right here on <class 'art.attacks.evasion.projected_gradient_descent.projected_gradient_descent.ProjectedGradientDescent'>
[2023-04-27 09:12:56,594] {logging_mixin.py:115} INFO - <function optimize_evasion_attack.<locals>.<lambda> at 0x7fdd0ec5fe60>
[2023-04-27 09:12:56,610] {logging_mixin.py:115} INFO - This is the attack : <class 'art.attacks.evasion.projected_gradient_descent.projected_gradient_descent.ProjectedGradientDescent'> and its HP : {'eps': 0.7512560804614951, 'random_eps': True}
[2023-04-27 09:12:56,658] {projected_gradient_descent.py:199} INFO - Creating adversarial samples.
[2023-04-27 09:12:56,708] {logging_mixin.py:115} WARNING - PGD - Batches:   0%|          | 0/7 [00:00<?, ?it/s]
[2023-04-27 09:13:10,589] {logging_mixin.py:115} WARNING - PGD - Batches:  14%|#4        | 1/7 [00:13<01:23, 13.88s/it]
[2023-04-27 09:13:16,334] {logging_mixin.py:115} WARNING - PGD - Batches:  29%|##8       | 2/7 [00:19<00:45,  9.10s/it]
[2023-04-27 09:13:23,276] {logging_mixin.py:115} WARNING - PGD - Batches:  43%|####2     | 3/7 [00:26<00:32,  8.11s/it]
[2023-04-27 09:13:36,690] {logging_mixin.py:115} WARNING - PGD - Batches:  57%|#####7    | 4/7 [00:39<00:30, 10.21s/it]
[2023-04-27 09:13:54,777] {logging_mixin.py:115} WARNING - PGD - Batches:  71%|#######1  | 5/7 [00:58<00:26, 13.05s/it]
[2023-04-27 09:14:29,781] {logging_mixin.py:115} WARNING - PGD - Batches:  86%|########5 | 6/7 [01:33<00:20, 20.51s/it]
[2023-04-27 09:14:42,358] {logging_mixin.py:115} WARNING - PGD - Batches: 100%|##########| 7/7 [01:45<00:00, 17.92s/it]
[2023-04-27 09:14:42,392] {logging_mixin.py:115} WARNING -                                                             
[2023-04-27 09:14:44,212] {projected_gradient_descent_pytorch.py:239} INFO - Success rate of attack: 52.28%
[2023-04-27 09:14:44,515] {logging_mixin.py:115} INFO - This is the attack : <class 'art.attacks.evasion.projected_gradient_descent.projected_gradient_descent.ProjectedGradientDescent'> and its HP : {'eps': 0.7968282303932671, 'random_eps': False}
[2023-04-27 09:14:44,527] {projected_gradient_descent.py:199} INFO - Creating adversarial samples.
[2023-04-27 09:14:44,761] {logging_mixin.py:115} WARNING - 
[2023-04-27 09:14:44,859] {logging_mixin.py:115} WARNING - PGD - Batches:   0%|          | 0/7 [00:00<?, ?it/s]
[2023-04-27 09:15:42,364] {logging_mixin.py:115} WARNING - PGD - Batches:  14%|#4        | 1/7 [00:57<05:45, 57.50s/it]
[2023-04-27 09:16:46,252] {logging_mixin.py:115} WARNING - PGD - Batches:  29%|##8       | 2/7 [02:01<05:06, 61.26s/it]
[2023-04-27 09:17:41,355] {logging_mixin.py:115} WARNING - PGD - Batches:  43%|####2     | 3/7 [02:56<03:53, 58.45s/it]
[2023-04-27 09:18:34,569] {logging_mixin.py:115} WARNING - PGD - Batches:  57%|#####7    | 4/7 [03:49<02:49, 56.38s/it]
[2023-04-27 09:19:37,628] {logging_mixin.py:115} WARNING - PGD - Batches:  71%|#######1  | 5/7 [04:52<01:57, 58.79s/it]
[2023-04-27 09:20:26,971] {logging_mixin.py:115} WARNING - PGD - Batches:  86%|########5 | 6/7 [05:42<00:55, 55.58s/it]
[2023-04-27 09:20:36,576] {logging_mixin.py:115} WARNING - PGD - Batches: 100%|##########| 7/7 [05:51<00:00, 40.55s/it]
[2023-04-27 09:20:36,591] {logging_mixin.py:115} WARNING -                                                             
[2023-04-27 09:20:38,751] {projected_gradient_descent_pytorch.py:239} INFO - Success rate of attack: 52.28%
[2023-04-27 09:20:38,824] {logging_mixin.py:115} INFO - This is the attack : <class 'art.attacks.evasion.projected_gradient_descent.projected_gradient_descent.ProjectedGradientDescent'> and its HP : {'eps': 0.9475746955306714, 'random_eps': True}
[2023-04-27 09:20:38,853] {projected_gradient_descent.py:199} INFO - Creating adversarial samples.
[2023-04-27 09:20:39,538] {logging_mixin.py:115} WARNING - 
[2023-04-27 09:20:39,551] {logging_mixin.py:115} WARNING - PGD - Batches:   0%|          | 0/7 [00:00<?, ?it/s]
[2023-04-27 09:21:05,887] {logging_mixin.py:115} WARNING - PGD - Batches:  14%|#4        | 1/7 [00:26<02:38, 26.33s/it]
[2023-04-27 09:21:19,062] {logging_mixin.py:115} WARNING - PGD - Batches:  29%|##8       | 2/7 [00:39<01:32, 18.59s/it]
[2023-04-27 09:21:36,147] {logging_mixin.py:115} WARNING - PGD - Batches:  43%|####2     | 3/7 [00:56<01:11, 17.90s/it]
[2023-04-27 09:22:03,526] {logging_mixin.py:115} WARNING - PGD - Batches:  57%|#####7    | 4/7 [01:23<01:04, 21.65s/it]
[2023-04-27 09:22:08,078] {logging_mixin.py:115} WARNING - PGD - Batches:  71%|#######1  | 5/7 [01:28<00:30, 15.48s/it]
[2023-04-27 09:22:10,132] {logging_mixin.py:115} WARNING - PGD - Batches:  86%|########5 | 6/7 [01:30<00:10, 10.92s/it]
[2023-04-27 09:22:14,109] {logging_mixin.py:115} WARNING - PGD - Batches: 100%|##########| 7/7 [01:34<00:00,  8.65s/it]
[2023-04-27 09:22:14,131] {logging_mixin.py:115} WARNING -                                                             
[2023-04-27 09:22:14,315] {projected_gradient_descent_pytorch.py:239} INFO - Success rate of attack: 52.28%
[2023-04-27 09:22:14,330] {logging_mixin.py:115} INFO - This is the attack : <class 'art.attacks.evasion.projected_gradient_descent.projected_gradient_descent.ProjectedGradientDescent'> and its HP : {'eps': 0.7502819789938607, 'random_eps': False}
[2023-04-27 09:22:14,341] {projected_gradient_descent.py:199} INFO - Creating adversarial samples.
[2023-04-27 09:22:14,891] {logging_mixin.py:115} WARNING - 
[2023-04-27 09:22:14,892] {logging_mixin.py:115} WARNING - PGD - Batches:   0%|          | 0/7 [00:00<?, ?it/s]
[2023-04-27 09:22:21,227] {logging_mixin.py:115} WARNING - PGD - Batches:  14%|#4        | 1/7 [00:06<00:38,  6.33s/it]
[2023-04-27 09:22:28,023] {logging_mixin.py:115} WARNING - PGD - Batches:  29%|##8       | 2/7 [00:13<00:33,  6.61s/it]
[2023-04-27 09:22:34,477] {logging_mixin.py:115} WARNING - PGD - Batches:  43%|####2     | 3/7 [00:19<00:26,  6.54s/it]
[2023-04-27 09:22:43,786] {logging_mixin.py:115} WARNING - PGD - Batches:  57%|#####7    | 4/7 [00:28<00:22,  7.63s/it]
[2023-04-27 09:22:44,911] {logging_mixin.py:115} WARNING - PGD - Batches:  71%|#######1  | 5/7 [00:30<00:10,  5.28s/it]
[2023-04-27 09:22:45,418] {logging_mixin.py:115} WARNING - PGD - Batches:  86%|########5 | 6/7 [00:30<00:03,  3.66s/it]
[2023-04-27 09:22:45,792] {logging_mixin.py:115} WARNING - PGD - Batches: 100%|##########| 7/7 [00:30<00:00,  2.59s/it]
[2023-04-27 09:22:45,801] {logging_mixin.py:115} WARNING -                                                             
[2023-04-27 09:22:45,942] {projected_gradient_descent_pytorch.py:239} INFO - Success rate of attack: 52.28%
[2023-04-27 09:22:45,943] {logging_mixin.py:115} INFO - This is the attack : <class 'art.attacks.evasion.projected_gradient_descent.projected_gradient_descent.ProjectedGradientDescent'> and its HP : {'eps': 0.47037148871406476, 'random_eps': True}
[2023-04-27 09:22:45,952] {projected_gradient_descent.py:199} INFO - Creating adversarial samples.
[2023-04-27 09:22:46,009] {logging_mixin.py:115} WARNING - 
[2023-04-27 09:22:46,031] {logging_mixin.py:115} WARNING - PGD - Batches:   0%|          | 0/7 [00:00<?, ?it/s]
[2023-04-27 09:22:48,932] {logging_mixin.py:115} WARNING - PGD - Batches:  14%|#4        | 1/7 [00:02<00:17,  2.90s/it]
[2023-04-27 09:23:00,993] {logging_mixin.py:115} WARNING - PGD - Batches:  29%|##8       | 2/7 [00:14<00:41,  8.29s/it]
[2023-04-27 09:23:10,966] {logging_mixin.py:115} WARNING - PGD - Batches:  43%|####2     | 3/7 [00:24<00:36,  9.06s/it]
[2023-04-27 09:23:20,090] {logging_mixin.py:115} WARNING - PGD - Batches:  57%|#####7    | 4/7 [00:34<00:27,  9.08s/it]
[2023-04-27 09:23:35,272] {logging_mixin.py:115} WARNING - PGD - Batches:  71%|#######1  | 5/7 [00:49<00:22, 11.28s/it]
[2023-04-27 09:23:48,836] {logging_mixin.py:115} WARNING - PGD - Batches:  86%|########5 | 6/7 [01:02<00:12, 12.06s/it]
[2023-04-27 09:23:51,792] {logging_mixin.py:115} WARNING - PGD - Batches: 100%|##########| 7/7 [01:05<00:00,  9.08s/it]
[2023-04-27 09:23:51,793] {logging_mixin.py:115} WARNING -                                                             
[2023-04-27 09:23:51,810] {projected_gradient_descent_pytorch.py:239} INFO - Success rate of attack: 52.28%
[2023-04-27 09:23:51,962] {logging_mixin.py:115} INFO - This is the attack : <class 'art.attacks.evasion.projected_gradient_descent.projected_gradient_descent.ProjectedGradientDescent'> and its HP : {'eps': 0.5547008896317622, 'random_eps': True}
[2023-04-27 09:23:51,963] {projected_gradient_descent.py:199} INFO - Creating adversarial samples.
[2023-04-27 09:23:52,050] {logging_mixin.py:115} WARNING - 
[2023-04-27 09:23:52,081] {logging_mixin.py:115} WARNING - PGD - Batches:   0%|          | 0/7 [00:00<?, ?it/s]
[2023-04-27 09:24:18,053] {logging_mixin.py:115} WARNING - PGD - Batches:  14%|#4        | 1/7 [00:25<02:35, 25.97s/it]
[2023-04-27 09:24:57,782] {logging_mixin.py:115} WARNING - PGD - Batches:  29%|##8       | 2/7 [01:05<02:50, 34.06s/it]
[2023-04-27 09:25:39,150] {logging_mixin.py:115} WARNING - PGD - Batches:  43%|####2     | 3/7 [01:47<02:29, 37.40s/it]
[2023-04-27 09:26:28,088] {logging_mixin.py:115} WARNING - PGD - Batches:  57%|#####7    | 4/7 [02:36<02:05, 41.96s/it]
[2023-04-27 09:27:34,484] {logging_mixin.py:115} WARNING - PGD - Batches:  71%|#######1  | 5/7 [03:42<01:41, 50.77s/it]
[2023-04-27 09:28:27,541] {logging_mixin.py:115} WARNING - PGD - Batches:  86%|########5 | 6/7 [04:35<00:51, 51.55s/it]
[2023-04-27 09:28:40,711] {logging_mixin.py:115} WARNING - PGD - Batches: 100%|##########| 7/7 [04:48<00:00, 39.00s/it]
[2023-04-27 09:28:40,720] {logging_mixin.py:115} WARNING -                                                             
[2023-04-27 09:28:42,542] {projected_gradient_descent_pytorch.py:239} INFO - Success rate of attack: 52.28%
[2023-04-27 09:28:42,545] {logging_mixin.py:115} INFO - This is the attack : <class 'art.attacks.evasion.projected_gradient_descent.projected_gradient_descent.ProjectedGradientDescent'> and its HP : {'eps': 0.9737960885178861, 'random_eps': False}
[2023-04-27 09:28:42,579] {projected_gradient_descent.py:199} INFO - Creating adversarial samples.
[2023-04-27 09:28:44,291] {logging_mixin.py:115} WARNING - 
[2023-04-27 09:28:44,300] {logging_mixin.py:115} WARNING - PGD - Batches:   0%|          | 0/7 [00:00<?, ?it/s]
[2023-04-27 09:29:30,015] {logging_mixin.py:115} WARNING - PGD - Batches:  14%|#4        | 1/7 [00:45<04:34, 45.71s/it]
[2023-04-27 09:30:22,822] {logging_mixin.py:115} WARNING - PGD - Batches:  29%|##8       | 2/7 [01:38<04:09, 49.88s/it]
[2023-04-27 09:31:32,181] {logging_mixin.py:115} WARNING - PGD - Batches:  43%|####2     | 3/7 [02:47<03:55, 58.78s/it]
[2023-04-27 09:32:12,206] {logging_mixin.py:115} WARNING - PGD - Batches:  57%|#####7    | 4/7 [03:27<02:34, 51.37s/it]
[2023-04-27 09:33:16,121] {logging_mixin.py:115} WARNING - PGD - Batches:  71%|#######1  | 5/7 [04:31<01:51, 55.90s/it]
[2023-04-27 09:34:21,371] {logging_mixin.py:115} WARNING - PGD - Batches:  86%|########5 | 6/7 [05:37<00:59, 59.08s/it]
[2023-04-27 09:34:33,358] {logging_mixin.py:115} WARNING - PGD - Batches: 100%|##########| 7/7 [05:49<00:00, 43.68s/it]
[2023-04-27 09:34:33,371] {logging_mixin.py:115} WARNING -                                                             
[2023-04-27 09:34:33,922] {projected_gradient_descent_pytorch.py:239} INFO - Success rate of attack: 52.28%
[2023-04-27 09:34:34,200] {logging_mixin.py:115} INFO - This is the attack : <class 'art.attacks.evasion.projected_gradient_descent.projected_gradient_descent.ProjectedGradientDescent'> and its HP : {'eps': 0.8660432259656865, 'random_eps': False}
[2023-04-27 09:34:34,201] {projected_gradient_descent.py:199} INFO - Creating adversarial samples.
[2023-04-27 09:34:35,661] {logging_mixin.py:115} WARNING - 
[2023-04-27 09:34:35,672] {logging_mixin.py:115} WARNING - PGD - Batches:   0%|          | 0/7 [00:00<?, ?it/s]
[2023-04-27 09:35:34,701] {logging_mixin.py:115} WARNING - PGD - Batches:  14%|#4        | 1/7 [00:58<05:53, 59.00s/it]
[2023-04-27 09:36:27,756] {logging_mixin.py:115} WARNING - PGD - Batches:  29%|##8       | 2/7 [01:52<04:37, 55.50s/it]
[2023-04-27 09:37:35,901] {logging_mixin.py:115} WARNING - PGD - Batches:  43%|####2     | 3/7 [03:00<04:05, 61.28s/it]
[2023-04-27 09:38:34,842] {logging_mixin.py:115} WARNING - PGD - Batches:  57%|#####7    | 4/7 [03:59<03:01, 60.35s/it]
[2023-04-27 09:52:53,958] {local_task_job.py:144} ERROR - Heartbeat time limit exceeded!
[2023-04-27 09:52:54,774] {process_utils.py:129} INFO - Sending Signals.SIGTERM to group 2862. PIDs of all processes in the group: [2862]
[2023-04-27 09:52:54,789] {process_utils.py:80} INFO - Sending the signal Signals.SIGTERM to group 2862
[2023-04-27 09:52:56,129] {taskinstance.py:1541} ERROR - Received SIGTERM. Terminating subprocesses.
[2023-04-27 09:52:56,134] {logging_mixin.py:115} WARNING -                                                             
[2023-04-27 09:52:57,197] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/attack_dag.py", line 571, in attack_ProjectedGradientDescent
    model_acc,adversarial_examples = attack(ProjectedGradientDescent)
  File "/opt/airflow/dags/attack_dag.py", line 643, in attack
    optimized_attack = optimize_evasion_attack(attack_obj,estimator,x_test,y_test)
  File "/opt/airflow/dags/attack_dag.py", line 619, in optimize_evasion_attack
    result = gp_minimize(func, search_space, n_calls=10)
  File "/home/airflow/.local/lib/python3.7/site-packages/skopt/optimizer/gp.py", line 268, in gp_minimize
    callback=callback, n_jobs=n_jobs, model_queue_size=model_queue_size)
  File "/home/airflow/.local/lib/python3.7/site-packages/skopt/optimizer/base.py", line 299, in base_minimize
    next_y = func(next_x)
  File "/opt/airflow/dags/attack_dag.py", line 617, in <lambda>
    func = lambda params: _optimize(attack, params,classifier=classifier,data=data,true_labels=true_labels)
  File "/opt/airflow/dags/attack_dag.py", line 609, in _optimize
    adv_examples = attack_to_optimize.generate(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent.py", line 200, in generate
    return self._attack.generate(x=x, y=y, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_pytorch.py", line 219, in generate
    x=batch, targets=batch_labels, mask=mask_batch, eps=batch_eps, eps_step=batch_eps_step
  File "/home/airflow/.local/lib/python3.7/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_pytorch.py", line 280, in _generate_batch
    adv_x, inputs, targets, mask, eps, eps_step, self.num_random_init > 0 and i_max_iter == 0, momentum
  File "/home/airflow/.local/lib/python3.7/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_pytorch.py", line 435, in _compute_pytorch
    perturbation = self._compute_perturbation_pytorch(x_adv, y, mask, momentum)
  File "/home/airflow/.local/lib/python3.7/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_pytorch.py", line 307, in _compute_perturbation_pytorch
    grad = self.estimator.loss_gradient(x=x, y=y) * (1 - 2 * int(self.targeted))
  File "/home/airflow/.local/lib/python3.7/site-packages/art/estimators/classification/pytorch.py", line 856, in loss_gradient
    loss.backward()
  File "/home/airflow/.local/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/home/airflow/.local/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1543, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2023-04-27 09:52:57,338] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=multi_attack_dag, task_id=attack_ProjectedGradientDescent, execution_date=20230427T090119, start_date=20230427T090934, end_date=20230427T095257
[2023-04-27 10:02:08,006] {process_utils.py:143} WARNING - process psutil.Process(pid=2862, name='airflow task ru', status='running', started='09:09:34') did not respond to SIGTERM. Trying SIGKILL
[2023-04-27 10:02:08,016] {process_utils.py:80} INFO - Sending the signal Signals.SIGKILL to group 2862
[2023-04-27 10:02:08,245] {process_utils.py:75} INFO - Process psutil.Process(pid=2862, name='airflow task ru', status='terminated', exitcode=<Negsignal.SIGKILL: -9>, started='09:09:34') (2862) terminated with exit code Negsignal.SIGKILL
[2023-04-27 10:02:08,253] {standard_task_runner.py:162} ERROR - Job 6473 was killed before it finished (likely due to running out of memory)
